import os
import glob
import torch
import numpy as np
from pathlib import Path
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset

# === Config ===
DEVICE = torch.device("cpu")
BATCH_SIZE = 64
EPOCHS = 20

# Dataset
class SyntheticPSDCaseDataset(Dataset):
    def __init__(self, data_list, label_list):
        x = np.stack([np.array(d) for d in data_list])      # (N,10,1,64,20)
        x = x.squeeze(2)                                   # (N,10,64,20)
        N, SU, H, W = x.shape
        x = x.reshape(N * SU, H, W)                        # (N*10,64,20)
        y = np.repeat(np.array(label_list), repeats=10, axis=0)

        self.X = torch.tensor(x, dtype=torch.float32)
        self.Y = torch.tensor(y, dtype=torch.float32)
        self.X = (self.X - self.X.mean()) / self.X.std()

    def __len__(self):  return len(self.X)
    def __getitem__(self, i): return self.X[i], self.Y[i]

# Model
class LSTMDetector(nn.Module):
    def __init__(self, num_classes=20):
        super().__init__()
        self.lstm = nn.LSTM(64, 128, 2, batch_first=True)
        self.fc   = nn.Linear(128, num_classes)
        self.sig  = nn.Sigmoid()
    def forward(self, x):
        x = x.permute(0,2,1)             # (B,20,64)
        out, _ = self.lstm(x)
        out    = self.fc(out[:,-1,:])
        return self.sig(out)

def evaluate_pd(model, loader, pfa=0.05):
    model.eval()
    ys, ps = [], []
    with torch.no_grad():
        for xb, yb in loader:
            xb, yb = xb.to(DEVICE), yb.to(DEVICE)
            ps.append(model(xb).cpu()); ys.append(yb.cpu())
    ys = torch.cat(ys).numpy().ravel()
    ps = torch.cat(ps).numpy().ravel()
    fpr, tpr, _ = roc_curve(ys, ps)
    idx = np.searchsorted(fpr, pfa, side="left")
    pd  = tpr[idx] if idx < len(tpr) else 0.0
    return pd, fpr, tpr   

def train_one_file(case_name, pth_file):
    db = torch.load(pth_file, map_location=DEVICE)
    print(f"✅ loaded {pth_file.name}  train={len(db['training data list'])}  "
          f"test={len(db['testing data list'])}")

    tr_loader = DataLoader(SyntheticPSDCaseDataset(db['training data list'],
                                                   db['training label list']),
                           batch_size=BATCH_SIZE, shuffle=True)
    te_loader = DataLoader(SyntheticPSDCaseDataset(db['testing data list'],
                                                   db['testing label list']),
                           batch_size=BATCH_SIZE)

    model = LSTMDetector().to(DEVICE)
    optim_ = optim.Adam(model.parameters(), lr=1e-3)
    lossfn = nn.BCELoss()

    for ep in range(EPOCHS):
        model.train(); tot = 0
        for xb, yb in tr_loader:
            xb, yb = xb.to(DEVICE), yb.to(DEVICE)
            loss   = lossfn(model(xb), yb)
            optim_.zero_grad(); loss.backward(); optim_.step()
            tot += loss.item()*xb.size(0)
        if (ep+1)%5==0: print(f"{case_name} {pth_file.stem} ep{ep+1}/{EPOCHS} "
                              f"loss={tot/len(tr_loader.dataset):.3f}")

    pd, fpr, tpr = evaluate_pd(model, te_loader)
    return pd, fpr, tpr

def run_case(case_dir, label):
    pd_dict, fpr_dict, tpr_dict = {}, {}, {}
    pths = sorted(glob.glob(str(case_dir/"Data_SNR*.pth")))
    if not pths: print(f"❌ no files in {case_dir}"); return pd_dict, fpr_dict, tpr_dict
    for p in pths:
        p   = Path(p)                               # ← convert string ➜ Path
        snr = int(p.stem.split("SNR")[1].split("vol")[0])   # e.g. -10
        pd, fpr, tpr = train_one_file(label, p)
        pd_dict[snr]  = pd
        fpr_dict[snr] = fpr
        tpr_dict[snr] = tpr

    return pd_dict, fpr_dict, tpr_dict

print("\n=== Case 4 (Random Mod) ===")
pd4, fpr4, tpr4 = run_case(CASE4_PATH, "Case4")
print("\n=== Case 5 (PU Switch) ===")
pd5, fpr5, tpr5 = run_case(CASE5_PATH, "Case5")

# --------  PD vs SNR plots  ----------
plt.figure(figsize=(7,5))
if pd4:
    x = sorted(pd4); y = [pd4[s] for s in x]
    plt.plot(x,y,'-o',label="Case 4")
plt.xlabel("SNR (dB)"); plt.ylabel("Probability of Detection (PD) @ PFA 5%")
plt.title("PD vs SNR"); plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()
plt.figure(figsize=(7,5))
if pd5:
    x = sorted(pd5); y = [pd5[s] for s in x]
    plt.plot(x,y,'-o',label="Case 5",color="purple")
plt.xlabel("SNR (dB)"); plt.ylabel("Probability of Detection (PD) @ PFA 5%")
plt.title("PD vs SNR"); plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()

# ------------------------------------------------------------------------
# --------  ROC curves @ -8 dB  ----------
plt.figure(figsize=(7,6))
# load Case‑3 ROC if model exists
try:
    model3 = LSTMDetector().to(DEVICE)
    model3.load_state_dict(torch.load("lstm_case3_snr-8_model.pt",map_location=DEVICE))
    db3 = torch.load(r"C:\Users\Srijita Saha\Collaborative learning\PartialObservation\RefinedNewData\SNRs\10m_Alpha5\250708_18_30\Data_SNR-8vol20.pth")
    tl3 = DataLoader(SyntheticPSDCaseDataset(db3['testing data list'], db3['testing label list']), batch_size=BATCH_SIZE)
    _, fpr3, tpr3 = evaluate_pd(model3, tl3)
    plt.plot(fpr3, tpr3, '--', label="Case 3 (SNR -8 dB)", color="green")
except Exception as e:
    print("⚠️ Case 3 ROC skipped:", e)

if -8 in fpr4:
    plt.plot(fpr4[-8], tpr4[-8], '-', label="Case 4 (SNR -8 dB)", color="orange")
if -8 in fpr5:
    plt.plot(fpr5[-8], tpr5[-8], '-', label="Case 5 (SNR -8 dB)", color="purple")

plt.xlabel("Probability of False Alarm (PFA)")
plt.ylabel("Probability of Detection (PD)")
plt.title("ROC Curves @ SNR = -8 dB")
plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()
